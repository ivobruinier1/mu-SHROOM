# FENJI at SemEval-2025 Task 3

## Overview
This repository contains the implementation of the FENJI system for the SemEval-2025 Mu-SHROOM shared task. The task focuses on character-level hallucination detection across 14 languages. Our approach utilizes Retrieval-Augmented Generation (RAG) and the FLAN-T5 model to identify hallucinated spans in text generated by instruction-tuned Large Language Models (LLMs).

## Features
- **Retrieval-Augmented Generation (RAG):** Uses Dense Passage Retrieval (DPR) to fetch relevant passages for context.
- **FLAN-T5 Model:** Processes retrieved passages to detect hallucination spans.
- **Multilingual Support:** Evaluates performance across 14 languages.
- **JSONL Data Processing:** Handles input and output in JSONL format.

## Installation
Follow these steps to set up and run the project:

```sh
# Clone the repository
git clone https://github.com/....

# Install the required dependencies
pip install -r requirements.txt

# Align the correlating test_set and passages in the FENJI_FINAL.py script

# Run the main script
python3 FENJI_FINAL.py
```

Upon successful execution, new JSONL files will be created in the format:
```sh
mushroom.labels.{language}.tst.jsonl
```
These files contain the detected hallucination spans.

## Dataset
The dataset is provided in JSONL format, where each entry contains:
- **Prompt:** The input query.
- **Generated Output:** The LLM-generated response.
- **Model ID:** Identifies the LLM used.
- **Annotations:** Includes soft and hard labels indicating hallucination spans.

## Model Pipeline
The system follows a structured pipeline:
1. **Named Entity Recognition (NER):** Extracts entities from input queries.
2. **Dense Passage Retrieval (DPR):** Fetches relevant Wikipedia passages.
3. **FLAN-T5 Prompting:** Identifies hallucinated spans.
4. **Evaluation:** Computes Intersection-over-Union (IoU) accuracy.

## Results
The system was evaluated across multiple languages using IoU as the primary metric. While RAG showed potential, its effectiveness depended on retrieval accuracy. The baseline "mark-all" approach outperformed our method in most cases.

## Limitations
- **Language-Specific Performance:** Non-alphabetical languages (e.g., Arabic, Farsi, Chinese) exhibited lower performance.
- **Span Detection Constraints:** The model struggled to detect multiple hallucination spans within a single response.
- **Retrieval Context Limitations:** Inaccurate retrieval negatively impacted performance.

## Future Work
- Improve retrieval context-awareness.
- Explore alternative generative models.
- Enhance overlap detection for better span identification.

## Contact
For questions or collaboration opportunities, reach out to:
- Flor Alberts ([f.alberts.2@student.rug.nl](mailto:f.alberts.2@student.rug.nl))
- Ivo Bruinier ([i.b.a.bruinier@student.rug.nl](mailto:i.b.a.bruinier@student.rug.nl))
- Nathalie de Palm ([n.h.m.de.palm@student.rug.nl](mailto:n.h.m.de.palm@student.rug.nl))
- Justin Paetzelt ([j.paetzelt@student.rug.nl](mailto:j.paetzelt@student.rug.nl))
- Erik Varecha ([e.varecha@student.rug.nl](mailto:e.varecha@student.rug.nl))

